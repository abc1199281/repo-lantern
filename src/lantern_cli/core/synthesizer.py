"""Synthesizer module for generating top-down documentation."""
import logging
from pathlib import Path
from typing import List

logger = logging.getLogger(__name__)


class Synthesizer:
    """Synthesizes analysis results into top-down documentation."""

    def __init__(self, root_path: Path) -> None:
        """Initialize Synthesizer.

        Args:
            root_path: Project root path.
        """
        self.root_path = root_path
        self.sense_dir = root_path / ".lantern" / "sense"
        self.output_dir = root_path / ".lantern" / "output" / "en" / "top_down"

    def load_sense_files(self) -> List[str]:
        """Load all .sense files from the sense directory.

        Returns:
            List of file contents.
        """
        contents = []
        if not self.sense_dir.exists():
            return contents

        # Glob all .sense files and sort them to maintain order
        for sense_file in sorted(self.sense_dir.glob("*.sense")):
            try:
                with open(sense_file, "r", encoding="utf-8") as f:
                    contents.append(f.read())
            except Exception as e:
                logger.warning(f"Failed to read {sense_file}: {e}")
        
        return contents

    def generate_top_down_docs(self) -> None:
        """Generate top-down documentation files."""
        contents = self.load_sense_files()
        if not contents:
            logger.warning("No analysis results found to synthesize.")
            return

        if not self.output_dir.exists():
            self.output_dir.mkdir(parents=True, exist_ok=True)

        # For MVP, we will use a naive aggregation strategy:
        # Concatenate all summaries and pretend we are generating distinct docs
        # In a real system, this would involve a secondary LLM pass 
        # (Map-Reduce or Summary-of-Summaries)
        
        aggregated_content = "\n\n".join(contents)
        
        self._generate_overview(aggregated_content)
        self._generate_architecture(aggregated_content)
        self._generate_getting_started(aggregated_content)
        self._generate_concepts(aggregated_content)

    def _generate_overview(self, content: str) -> None:
        """Generate OVERVIEW.md."""
        header = "# Project Overview\n\n> Generated by Lantern\n\n## Vision & Scope\n\n"
        self._write_doc("OVERVIEW.md", header + content)

    def _generate_architecture(self, content: str) -> None:
        """Generate ARCHITECTURE.md."""
        header = "# System Architecture\n\n> Generated by Lantern\n\n## Module Design\n\n"
        self._write_doc("ARCHITECTURE.md", header + content)

    def _generate_getting_started(self, content: str) -> None:
        """Generate GETTING_STARTED.md."""
        header = "# Getting Started\n\n> Generated by Lantern\n\n## Onboarding\n\n"
        self._write_doc("GETTING_STARTED.md", header + content)

    def _generate_concepts(self, content: str) -> None:
        """Generate CONCEPTS.md."""
        header = "# Core Concepts\n\n> Generated by Lantern\n\n## Key Abstractions\n\n"
        self._write_doc("CONCEPTS.md", header + content)

    def _write_doc(self, filename: str, content: str) -> None:
        """Write content to a file."""
        file_path = self.output_dir / filename
        
        # Truncate for sanity in MVP
        if len(content) > 10000:
             content = content[:10000] + "\n\n...(truncated)..."

        with open(file_path, "w", encoding="utf-8") as f:
            f.write(content)
