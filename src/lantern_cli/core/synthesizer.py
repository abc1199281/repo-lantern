"""Synthesizer module for generating top-down documentation."""
import logging
from pathlib import Path
from typing import List, Optional

logger = logging.getLogger(__name__)


class Synthesizer:
    """Synthesizes analysis results into top-down documentation."""

    def __init__(self, root_path: Path, language: str = "en", output_dir: Optional[str] = None) -> None:
        """Initialize Synthesizer.

        Args:
            root_path: Project root path.
            language: Output language code (default: en).
        """
        self.root_path = root_path
        self.language = language
        base_out = output_dir or ".lantern"
        self.base_output_dir = root_path / base_out
        self.sense_dir = self.base_output_dir / "sense"
        self.output_dir = self.base_output_dir / "output" / language / "top_down"

    def load_sense_files(self) -> List[str]:
        """Load all .sense files from the sense directory.

        Returns:
            List of file contents.
        """
        contents = []
        if not self.sense_dir.exists():
            return contents

        # Glob all .sense files and sort them to maintain order
        for sense_file in sorted(self.sense_dir.glob("*.sense")):
            try:
                with open(sense_file, "r", encoding="utf-8") as f:
                    contents.append(f.read())
            except Exception as e:
                logger.warning(f"Failed to read {sense_file}: {e}")
        
        return contents

    def generate_top_down_docs(self) -> None:
        """Generate top-down documentation files."""
        contents = self.load_sense_files()
        if not contents:
            logger.warning("No analysis results found to synthesize.")
            return

        if not self.output_dir.exists():
            self.output_dir.mkdir(parents=True, exist_ok=True)

        # Generate distinct documents by extracting different aspects
        aggregated_content = "\n\n".join(contents)
        
        self._generate_overview(aggregated_content)
        self._generate_architecture(aggregated_content)
        self._generate_getting_started(aggregated_content)
        self._generate_concepts(aggregated_content)

    def _generate_overview(self, content: str) -> None:
        """Generate OVERVIEW.md focusing on project vision and scope."""
        header = "# Project Overview\n\n> Generated by Lantern\n\n"
        header += "## Vision & Scope\n\nThis document provides a high-level overview of the project structure and purpose.\n\n"
        header += "## Analysis Summary\n\n"
        self._write_doc("OVERVIEW.md", header + self._extract_section(content, "summary"))

    def _generate_architecture(self, content: str) -> None:
        """Generate ARCHITECTURE.md focusing on system design and modules."""
        header = "# System Architecture\n\n> Generated by Lantern\n\n"
        header += "## Module Design\n\nThis document describes the architectural components and their relationships.\n\n"
        header += "## Key Components\n\n"
        self._write_doc("ARCHITECTURE.md", header + self._extract_section(content, "architecture"))

    def _generate_getting_started(self, content: str) -> None:
        """Generate GETTING_STARTED.md focusing on entry points and setup."""
        header = "# Getting Started\n\n> Generated by Lantern\n\n"
        header += "## Onboarding Guide\n\nThis guide helps new developers understand how to get started with this codebase.\n\n"
        header += "## Key Entry Points\n\n"
        self._write_doc("GETTING_STARTED.md", header + self._extract_section(content, "entry_points"))

    def _generate_concepts(self, content: str) -> None:
        """Generate CONCEPTS.md focusing on core abstractions and patterns."""
        header = "# Core Concepts\n\n> Generated by Lantern\n\n"
        header += "## Key Abstractions\n\nThis document covers fundamental concepts and design patterns used in the codebase.\n\n"
        header += "## Important Abstractions\n\n"
        self._write_doc("CONCEPTS.md", header + self._extract_section(content, "concepts"))

    def _extract_section(self, content: str, section_type: str) -> str:
        """Extract content relevant to a specific section type.
        
        Args:
            content: Aggregated content from all sense files.
            section_type: Type of section ('summary', 'architecture', 'entry_points', 'concepts').
            
        Returns:
            Content tailored to the section type.
        """
        lines = content.split("\n")
        relevant_lines = []
        
        # Extract lines based on section type
        for line in lines:
            if section_type == "summary" and any(kw in line.lower() for kw in ["batch", "summary", "overview"]):
                relevant_lines.append(line)
            elif section_type == "architecture" and any(kw in line.lower() for kw in ["module", "component", "dependency", "import"]):
                relevant_lines.append(line)
            elif section_type == "entry_points" and any(kw in line.lower() for kw in ["main", "entry", "init", "__init__", "cli"]):
                relevant_lines.append(line)
            elif section_type == "concepts" and any(kw in line.lower() for kw in ["class", "function", "design", "pattern", "interface"]):
                relevant_lines.append(line)
        
        # If no relevant lines found, return portion of content for variety
        if not relevant_lines:
            threshold = len(lines) * (0.75 if section_type == "summary" else 0.5)
            relevant_lines = lines[:int(threshold)]
        
        return "\n".join(relevant_lines) if relevant_lines else content

    def _write_doc(self, filename: str, content: str) -> None:
        """Write content to a file."""
        file_path = self.output_dir / filename
        
        # Truncate for sanity in MVP
        if len(content) > 10000:
             content = content[:10000] + "\n\n...(truncated)..."

        with open(file_path, "w", encoding="utf-8") as f:
            f.write(content)
