# Lantern

> **Lighting your way through the code forest.**

[English] | [ç¹é«”ä¸­æ–‡](README_zh-TW.md)

![Lantern Hero Image](assets/lantern.jpg)

**Lantern is your CLI mentor that turns complex repositories into a step-by-step narrative.**

Understand codebases faster with AI-guided architecture scans, planned learning paths, and human-readable guides.

**Speaks Your Language**: Complex logic is hard enough. Lantern explains code in your native language (Chinese, Japanese, Spanish, etc.) while keeping technical terms precise.

### âœ¨ Highlights

| | |
| :--- | :--- |
| ðŸ§  **Cognitive Load Reduction** | Psychology-based chunking (Miller's Law) breaks analysis into digestible batches |
| ðŸŒ **Native Language Output** | Technical docs in your mother tongueâ€”Chinese, Japanese, Spanish, and more |
| ðŸ“ˆ **Flow Reconstruction** | Sequence diagrams showing `request â†’ service â†’ db â†’ response` |
| ðŸ’¡ **Concept Extraction** | Key mental models: authentication flow, caching strategy, retry mechanisms |
| ðŸ“Š **Visual Scaffolding** | Mermaid architecture diagrams + sequence diagrams |
| ðŸ”’ **Local & Private** | CLI-native, no cloud uploadsâ€”safe for enterprise codebases |

---

# Why Lantern exists

Understanding a new codebase is hard.

You usually face:
* Not knowing which file to start with.
* Outdated or non-existent documentation.
* Hidden architectural dependencies.
* Needing to read dozens of files to understand one concept.

**The AI Code Problem**

In 2024+, codebases are increasingly filled with AI-generated code that:
* Works, but nobody fully understands *why*
* Lacks meaningful comments or documentation
* Makes legacy code comprehension even harder

Most AI tools help you:
* Write code.
* Refactor code.

**Lantern's goal is different:**
> Lantern helps you **understand** codeâ€”whether written by humans or AI.

---

# Use Cases

| Scenario | How Lantern Helps |
| :--- | :--- |
| ðŸ‘¤ **New Hire Onboarding** | Rapidly understand complex legacy systems without tribal knowledge |
| ðŸ”§ **Pre-Refactoring Analysis** | Assess impact scope before making changes |
| âš ï¸ **Technical Debt Assessment** | Identify high-risk modules and hidden dependencies |
| ðŸ—ï¸ **Architecture Decision Support** | Make better design choices with clear system visibility |
| ðŸ” **Code Review Preparation** | Understand unfamiliar code before reviewing PRs |

---

# Key Features

### ðŸ§  Psychology-Driven Design
Not just documentationâ€”**designed for human comprehension**. Chunking, scaffolding, and native language output reduce cognitive load.

### ðŸ”„ Dual-Perspective Analysis
**Bottom-up** (file-by-file details) + **Top-down** (architecture overview) = complete understanding from any angle.

### ðŸ”Œ Adaptable Backends
Works with your preferred AI CLI: Codex, Gemini, Claude. Swap backends without changing your workflow.

### âœï¸ Human-in-the-Loop
Review and edit `lantern_plan.md` before execution. You control what gets analyzed and how.


# What Lantern Does

**One command. Full documentation.**

```bash
lantern run
```

Lantern analyzes your repository and generates a **complete documentation repository**:

![Lantern Input & Output](assets/input_output.png)

### Input
```
path to repo
```

### Output
```
.lantern/output/
â”œâ”€â”€ en/
â”‚   â”œâ”€â”€ top_down/                    # ðŸ“– High-level guides
â”‚   â”‚   â”œâ”€â”€ OVERVIEW.md             # Project vision & scope
â”‚   â”‚   â”œâ”€â”€ ARCHITECTURE.md         # System design & module relationships
â”‚   â”‚   â”œâ”€â”€ CONCEPTS.md             # Key concepts (auth flow, caching, retry)
â”‚   â”‚   â”œâ”€â”€ FLOWS.md                # Critical data flows (Sequence Diagrams)
â”‚   â”‚   â””â”€â”€ GETTING_STARTED.md      # Onboarding guide
â”‚   â”‚
â”‚   â””â”€â”€ bottom_up/                   # ðŸ“ File-by-file analysis
â”‚       â””â”€â”€ src/                     # Mirrors your repo structure
â”‚           â”œâ”€â”€ kernel/
â”‚           â”‚   â”œâ”€â”€ scheduler.py.md  # Detailed breakdown
â”‚           â”‚   â””â”€â”€ events.py.md
â”‚           â””â”€â”€ api/
â”‚               â””â”€â”€ routes.py.md
â”‚
â””â”€â”€ zh-TW/                           # ðŸŒ Native language version
    â””â”€â”€ (same structure)
```

### How It Maintains Quality

Internally, Lantern uses **batch-based analysis** for quality control:
- Files are analyzed in small batches (1-3 related files)
- Each batch builds on context from previous batches
- This ensures **traceability** and **consistent reasoning**

You don't need to manage thisâ€”just run `lantern run` and let it work.

---

# Key Ideas

Lantern is built on psychological design principles:

### Chunking (Miller's Law)
We strictly limit each analysis batch to ~3 related files to prevent cognitive information overload.

### Scaffolding
By generating a plan first and allowing for human review, we build a steady ladder for understanding complex systems.

### Human-First Output
Final outputs are designed for human reading, not machine consumption, focusing on "Why" and "How" rather than just "What".

---

# Quick Start

## Prerequisites

Lantern requires one of the following AI CLI tools installed:

| CLI Tool | Installation |
| :--- | :--- |
| **Codex CLI** | `npm install -g @openai/codex` |
| **Gemini CLI** | `npm install -g @anthropic/gemini-cli` |
| **Claude Code** | `npm install -g @anthropic/claude-code` |

Lantern auto-detects available CLI backends.

## Installation

```bash
pip install lantern-cli
```

## Simple Mode (Recommended)

```bash
# Run in current directory (outputs to .lantern/)
lantern run

# Specify input and output
lantern run --repo ~/projects/my-app --output ~/docs/my-app-docs
```

Lantern auto-detects available CLI backends: `codex` â†’ `gemini` â†’ `claude`

## Advanced Mode

For reviewing the analysis plan before execution:

```bash
# Step 1: Initialize
lantern init --repo /path/to/repo

# Step 2: Generate plan (review lantern_plan.md)
lantern plan

# Step 3: Execute analysis
lantern run
```

## Specify Backend

```bash
lantern run --backend claude
lantern run --backend gemini
```

---

# Real Example

Analyzing [accellera-official/systemc](https://github.com/accellera-official/systemc):

**Top-down output** (`ARCHITECTURE.md`):
> SystemC is effectively a **co-operative multitasking OS** specialized for hardware simulation.
> At its core lies the `sc_simcontext`, which acts as the kernel, scheduler, and event manager.

**Bottom-up output** (`sc_simcontext.md`):
> `sc_simcontext` is the **central nervous system** of the SystemC simulation kernel.
> It manages: Global Simulation State, Object Registry, Scheduler, Process Management.

---

# Example: Lantern Analyzes Itself

Here is a summary of the architecture report generated by Lantern analyzing its own codebase (`lantern-cli`):

### [Generated] Project Overview

**Lantern CLI** is a Python-based command-line tool designed to help developers rapidly understand unfamiliar codebases.

#### Core Architecture
The system uses a **Pipeline Pattern**, consisting of the following primary modules:

1.  **CLI Layer (`src/lantern_cli/cli`)**
    -   Uses the `Typer` framework to handle command-line inputs (`main.py`).
    -   Orchestrates the execution flow of `init`, `plan`, and `run` commands.

2.  **Core Layer (`src/lantern_cli/core`)**
    -   **Architect (`architect.py`)**: Acts as the planner, analyzing the `DependencyGraph` and generating a batched analysis plan (`lantern_plan.md`).
    -   **Runner (`runner.py`)**: Acts as the executor, communicating with LLM backends, executing batch analysis, and handling state persistence (`StateManager`) for resume capability.
    -   **Synthesizer (`synthesizer.py`)**: Acts as the synthesizer, aggregating scattered batch analysis results (`.sense` files) into final Top-down documentation.

3.  **Backend Adapter Layer (`src/lantern_cli/backends`)**
    -   Implements the Strategy Pattern via `BackendFactory`.
    -   Supports multiple LLM backends: `CodexAdapter`, `GeminiAdapter`, `ClaudeAdapter`.
    -   Abstracts away the invocation details of different CLI tools.

---

# Configuration

## Language settings

You can set your preferred output language (e.g., Traditional Chinese, Japanese) to lower the cognitive barrier even further.

**Option A: Command line**
```bash
lantern run --lang zh-TW
```

---

# Supported Agents

Lantern drives your favorite CLI agents:
* Claude Code
* Gemini CLI (Antigravity)
* Open-source local runners

---

# Roadmap

- [ ] **Execution Trace Mode**: Collect call graphs via unit tests for dynamic analysis.
- [ ] **Memory Cross-talk**: Enhanced reasoning across batch boundaries.
- [ ] **Multi-language Static Analysis**: Go, Rust, and Java support.
- [ ] **VSCode Extension**: Integrated progress tracking.

---

# Contributing

PRs are welcome! Help us build the ultimate tool for code understanding.

---

# License

MIT
